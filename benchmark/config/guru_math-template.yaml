mode: both
project: Trinity-RFT
group: ${oc.env:TRINITY_GROUP,guru_math-bench}
name: ${oc.env:TRINITY_NAME,guru_math}
checkpoint_root_dir: placeholder
model:
  model_path: Qwen/Qwen2.5-7B
  max_prompt_tokens: 4096
  max_response_tokens: 8192
algorithm:
  algorithm_type: grpo
  repeat_times: 16
  kl_loss_fn_args:
    kl_coef: 0.0
  optimizer:
    lr: 1e-6
    weight_decay: 0.1
    lr_warmup_steps: 80
    warmup_style: constant
cluster:
  node_num: 1
  gpu_per_node: 8
data_processor:
  experience_pipeline:
    save_input: false
buffer:
  total_epochs: 1
  batch_size: 60
  explorer_input:
    default_workflow_type: math_boxed_workflow
    default_reward_fn_type: math_boxed_reward_naive_dapo
    taskset:
      name: math
      storage_type: file
      path: null
      format:
        prompt_key: question
        response_key: ground_truth
        system_prompt: "You are a helpful assistant. To answer a query from the user, please first thinks through the question step-by-step inside <think>...</think>, then provides the final response to user."
        reply_prefix: "<think>"
      rollout_args:
        temperature: 1.0
        logprobs: 0
    eval_tasksets: []
  trainer_input:
    experience_buffer:
      name: math_buffer
      storage_type: queue
      replay_buffer:
        enable: false
explorer:
  eval_interval: 10
  runner_per_model: 8
  rollout_model:
    engine_type: vllm_async
    engine_num: 3
    tensor_parallel_size: 1
    enable_prefix_caching: false
    enforce_eager: false
    dtype: bfloat16
    seed: 42
synchronizer:
  sync_style: fixed
  sync_method: nccl
  sync_interval: 8
  sync_timeout: 2400
trainer:
  trainer_type: verl
  save_interval: 80
  enable_preview: true
  grad_clip: 1.0
  max_token_len_per_gpu: 24576
monitor:
  monitor_type: wandb
