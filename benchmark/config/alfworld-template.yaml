mode: both
project: Trinity-RFT
group: ${oc.env:TRINITY_GROUP,os-bench}
name: ${oc.env:TRINITY_NAME,alfworld}
checkpoint_root_dir: placeholder
algorithm:
  algorithm_type: grpo
  repeat_times: 8
  loss_agg_mode: "token-mean"
  optimizer:
    lr: 1e-6
  sample_strategy: default
  policy_loss_fn: ppo
  advantage_fn: grpo
  kl_penalty_fn: none
  kl_loss_fn: k2
  entropy_loss_fn: default
  kl_loss_fn_args:
    kl_coef: 0.001
data_processor: {}
model:
  model_path: placeholder
  max_prompt_tokens: 10240
  max_response_tokens: 4096
cluster:
  node_num: 1
  gpu_per_node: 8
buffer:
  batch_size: 32
  total_epochs: 5
  explorer_input:
    taskset:
      name: alfworld
      split: train
      storage_type: file
      path: null
      format:
        prompt_key: 'game_file'
      rollout_args:
        temperature: 1.0
        logprobs: 0
    eval_tasksets:
      - name: alfworld
        split: test
        storage_type: file
        path: null
        format:
          prompt_key: 'game_file'
        rollout_args:
          temperature: 1.0
          logprobs: 0
    default_workflow_type: 'alfworld_workflow'
explorer:
  eval_on_startup: true
  eval_interval: 10
  runner_per_model: 8
  max_timeout: 3600
  max_retry_times: 2
  rollout_model:
    engine_num: 4
    tensor_parallel_size: 1
    enforce_eager: false
    enable_prefix_caching: false
    enable_chunked_prefill: true
    gpu_memory_utilization: 0.7
    dtype: bfloat16
    seed: 42
    enable_thinking: false
    enable_openai_api: false
  auxiliary_models: []
  bench_on_latest_checkpoint: true
trainer:
  trainer_type: verl
  save_interval: 1000
  enable_preview: true
  grad_clip: 1.0
  use_dynamic_bsz: true
  max_token_len_per_gpu: 16384
  ulysses_sequence_parallel_size: 1
monitor:
  monitor_type: wandb
synchronizer:
  sync_method: nccl
  sync_style: fixed
  sync_interval: 1
  sync_timeout: 3600
