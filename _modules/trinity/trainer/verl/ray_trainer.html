

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>trinity.trainer.verl.ray_trainer &mdash; Trinity-RFT 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            Trinity-RFT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial/example_reasoning_basic.html">A quick example with GSM8k</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial/example_reasoning_advanced.html">Example: off-policy RFT mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial/example_multi_turn.html">Example: Multi-Turn RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial/example_dpo.html">Example: Run DPO on Human-Like-DPO-Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial/example_data_functionalities.html">Data processing functionalities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial/trinity_configs.html">Trinity-RFT Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial/trinity_programming_guide.html">Trinity-RFT Developer Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../build_api/trinity.buffer.html">trinity.buffer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build_api/trinity.explorer.html">trinity.explorer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build_api/trinity.trainer.html">trinity.trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build_api/trinity.manager.html">trinity.manager</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build_api/trinity.common.html">trinity.common</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build_api/trinity.utils.html">trinity.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Trinity-RFT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">trinity.trainer.verl.ray_trainer</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for trinity.trainer.verl.ray_trainer</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2024 Bytedance Ltd. and/or its affiliates</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Modified from ray_trainer.py</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">uuid</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">contextlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">contextmanager</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">enum</span><span class="w"> </span><span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pprint</span><span class="w"> </span><span class="kn">import</span> <span class="n">pprint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Type</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">codetiming</span><span class="w"> </span><span class="kn">import</span> <span class="n">Timer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">omegaconf</span><span class="w"> </span><span class="kn">import</span> <span class="n">OmegaConf</span><span class="p">,</span> <span class="n">open_dict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomSampler</span><span class="p">,</span> <span class="n">SequentialSampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchdata.stateful_dataloader</span><span class="w"> </span><span class="kn">import</span> <span class="n">StatefulDataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProto</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.protocol</span><span class="w"> </span><span class="kn">import</span> <span class="n">pad_dataproto_to_divisor</span><span class="p">,</span> <span class="n">unpad_dataproto</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.single_controller.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">Worker</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.single_controller.ray</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">RayClassWithInitArgs</span><span class="p">,</span>
    <span class="n">RayResourcePool</span><span class="p">,</span>
    <span class="n">RayWorkerGroup</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.single_controller.ray.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_colocated_worker_cls</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.trainer.ppo.metric_utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_data_metrics</span><span class="p">,</span>
    <span class="n">compute_throughout_metrics</span><span class="p">,</span>
    <span class="n">compute_timing_metrics</span><span class="p">,</span>
    <span class="n">reduce_metrics</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.checkpoint.checkpoint_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">find_latest_ckpt_path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.dataset.rl_dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">RLHFDataset</span><span class="p">,</span> <span class="n">collate_fn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.seqlen_balancing</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_seqlen_balanced_partitions</span><span class="p">,</span>
    <span class="n">log_seqlen_unbalance</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.torch_functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">masked_mean</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.tracking</span><span class="w"> </span><span class="kn">import</span> <span class="n">ValidationGenerationsLogger</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">trinity.common.constants</span><span class="w"> </span><span class="kn">import</span> <span class="n">AlgorithmType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">trinity.trainer.verl</span><span class="w"> </span><span class="kn">import</span> <span class="n">core_algos</span>

<span class="n">WorkerType</span> <span class="o">=</span> <span class="n">Type</span><span class="p">[</span><span class="n">Worker</span><span class="p">]</span>


<div class="viewcode-block" id="Role">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.Role">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Role</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    To create more roles dynamically, you can subclass Role and add new members</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">Actor</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">Rollout</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">ActorRollout</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">Critic</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">RefPolicy</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">RewardModel</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">ActorRolloutRef</span> <span class="o">=</span> <span class="mi">6</span></div>



<div class="viewcode-block" id="AdvantageEstimator">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.AdvantageEstimator">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AdvantageEstimator</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Using an enumeration class to avoid spelling errors in adv_estimator</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">GAE</span> <span class="o">=</span> <span class="s2">&quot;gae&quot;</span>
    <span class="n">GRPO</span> <span class="o">=</span> <span class="s2">&quot;grpo&quot;</span>
    <span class="n">REINFORCE_PLUS_PLUS</span> <span class="o">=</span> <span class="s2">&quot;reinforce_plus_plus&quot;</span>
    <span class="n">REMAX</span> <span class="o">=</span> <span class="s2">&quot;remax&quot;</span>
    <span class="n">RLOO</span> <span class="o">=</span> <span class="s2">&quot;rloo&quot;</span></div>



<div class="viewcode-block" id="ResourcePoolManager">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.ResourcePoolManager">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ResourcePoolManager</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define a resource pool specification. Resource pool will be initialized first.</span>
<span class="sd">    Mapping</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">resource_pool_spec</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span>
    <span class="n">mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Role</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>
    <span class="n">resource_pool_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">RayResourcePool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">dict</span><span class="p">)</span>

<div class="viewcode-block" id="ResourcePoolManager.create_resource_pool">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.ResourcePoolManager.create_resource_pool">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_resource_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">resource_pool_name</span><span class="p">,</span> <span class="n">process_on_nodes</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_spec</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># max_colocate_count means the number of WorkerGroups (i.e. processes) in each RayResourcePool</span>
            <span class="c1"># For FSDP backend, we recommend using max_colocate_count=1 that merge all WorkerGroups into one.</span>
            <span class="c1"># For Megatron backend, we recommend using max_colocate_count&gt;1 that can utilize different WorkerGroup for differnt models</span>
            <span class="n">resource_pool</span> <span class="o">=</span> <span class="n">RayResourcePool</span><span class="p">(</span>
                <span class="n">process_on_nodes</span><span class="o">=</span><span class="n">process_on_nodes</span><span class="p">,</span>
                <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">max_colocate_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">name_prefix</span><span class="o">=</span><span class="n">resource_pool_name</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_dict</span><span class="p">[</span><span class="n">resource_pool_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">resource_pool</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_check_resource_available</span><span class="p">()</span></div>


<div class="viewcode-block" id="ResourcePoolManager.get_resource_pool">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.ResourcePoolManager.get_resource_pool">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_resource_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">role</span><span class="p">:</span> <span class="n">Role</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RayResourcePool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the resource pool of the worker_cls&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">mapping</span><span class="p">[</span><span class="n">role</span><span class="p">]]</span></div>


<div class="viewcode-block" id="ResourcePoolManager.get_n_gpus">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.ResourcePoolManager.get_n_gpus">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_n_gpus</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the number of gpus in this cluster.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">n_gpus</span>
                <span class="k">for</span> <span class="n">process_on_nodes</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_spec</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">n_gpus</span> <span class="ow">in</span> <span class="n">process_on_nodes</span>
            <span class="p">]</span>
        <span class="p">)</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_check_resource_available</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if the resource pool can be satisfied in this ray cluster.&quot;&quot;&quot;</span>
        <span class="n">node_available_resources</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">available_resources_per_node</span><span class="p">()</span>
        <span class="n">node_available_gpus</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">node</span><span class="p">:</span> <span class="n">node_info</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;GPU&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">node_info</span> <span class="ow">in</span> <span class="n">node_available_resources</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>

        <span class="c1"># check total required gpus can be satisfied</span>
        <span class="n">total_available_gpus</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">node_available_gpus</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">total_required_gpus</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">n_gpus</span>
                <span class="k">for</span> <span class="n">process_on_nodes</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_spec</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">n_gpus</span> <span class="ow">in</span> <span class="n">process_on_nodes</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">total_available_gpus</span> <span class="o">&lt;</span> <span class="n">total_required_gpus</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Total available GPUs </span><span class="si">{</span><span class="n">total_available_gpus</span><span class="si">}</span><span class="s2"> is less than total desired GPUs </span><span class="si">{</span><span class="n">total_required_gpus</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># check each resource pool can be satisfied, O(#resource_pools * #nodes)</span>
        <span class="k">for</span> <span class="n">resource_pool_name</span><span class="p">,</span> <span class="n">process_on_nodes</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_spec</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">num_gpus</span><span class="p">,</span> <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">process_on_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">process_on_nodes</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">available_gpus</span> <span class="ow">in</span> <span class="n">node_available_gpus</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">available_gpus</span> <span class="o">&gt;=</span> <span class="n">num_gpus</span><span class="p">:</span>
                    <span class="n">node_available_gpus</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">-=</span> <span class="n">num_gpus</span>
                    <span class="n">num_nodes</span> <span class="o">-=</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="k">break</span>
            <span class="k">if</span> <span class="n">num_nodes</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Resource pool </span><span class="si">{</span><span class="n">resource_pool_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">num_gpus</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2"> cannot be satisfied in this ray cluster&quot;</span>
                <span class="p">)</span></div>



<div class="viewcode-block" id="apply_kl_penalty">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.apply_kl_penalty">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">apply_kl_penalty</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">kl_ctrl</span><span class="p">:</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">AdaptiveKLController</span><span class="p">,</span> <span class="n">kl_penalty</span><span class="o">=</span><span class="s2">&quot;kl&quot;</span><span class="p">):</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
    <span class="n">response_length</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">token_level_scores</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">batch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
    <span class="c1"># response_mask = attention_mask[:, -response_length:]</span>
    <span class="n">response_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">response_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="o">-</span><span class="n">response_length</span><span class="p">:]</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># compute kl between ref_policy and current policy</span>
    <span class="k">if</span> <span class="s2">&quot;ref_log_prob&quot;</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">kld</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">kl_penalty</span><span class="p">(</span>
            <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;old_log_probs&quot;</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;ref_log_prob&quot;</span><span class="p">],</span> <span class="n">kl_penalty</span><span class="o">=</span><span class="n">kl_penalty</span>
        <span class="p">)</span>  <span class="c1"># (batch_size, response_length)</span>
        <span class="n">kld</span> <span class="o">=</span> <span class="n">kld</span> <span class="o">*</span> <span class="n">response_mask</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">kl_ctrl</span><span class="o">.</span><span class="n">value</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">kld</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">response_mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">token_level_rewards</span> <span class="o">=</span> <span class="n">token_level_scores</span> <span class="o">-</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">kld</span>

    <span class="n">current_kl</span> <span class="o">=</span> <span class="n">masked_mean</span><span class="p">(</span><span class="n">kld</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">response_mask</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># average over sequence</span>
    <span class="n">current_kl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">current_kl</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="c1"># according to https://github.com/huggingface/trl/blob/951ca1841f29114b969b57b26c7d3e80a39f75a0/trl/trainer/ppo_trainer.py#L837</span>
    <span class="n">kl_ctrl</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">current_kl</span><span class="o">=</span><span class="n">current_kl</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">token_level_rewards</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;critic/kl&quot;</span><span class="p">:</span> <span class="n">current_kl</span><span class="p">,</span> <span class="s2">&quot;critic/kl_coeff&quot;</span><span class="p">:</span> <span class="n">beta</span><span class="p">}</span>

    <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">metrics</span></div>



<div class="viewcode-block" id="compute_response_mask">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.compute_response_mask">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_response_mask</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">):</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
    <span class="n">response_length</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="o">-</span><span class="n">response_length</span><span class="p">:]</span></div>



<div class="viewcode-block" id="compute_advantage">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.compute_advantage">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_advantage</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extend verl&#39;s original compute_advantage with OPMD&quot;&quot;&quot;</span>

    <span class="n">algorithm_type</span><span class="p">:</span> <span class="n">AlgorithmType</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;algorithm_type&quot;</span><span class="p">,</span> <span class="n">AlgorithmType</span><span class="o">.</span><span class="n">PPO</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">algorithm_type</span> <span class="o">==</span> <span class="n">AlgorithmType</span><span class="o">.</span><span class="n">OPMD</span><span class="p">:</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tau&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">opmd_baseline</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;opmd_baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">compute_advantage_opmd</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">tau</span><span class="o">=</span><span class="n">tau</span><span class="p">,</span>
            <span class="n">opmd_baseline</span><span class="o">=</span><span class="n">opmd_baseline</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">algorithm_type</span> <span class="o">==</span> <span class="n">AlgorithmType</span><span class="o">.</span><span class="n">PAIRWISE_OPMD</span><span class="p">:</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">data</span>

    <span class="k">elif</span> <span class="n">algorithm_type</span><span class="o">.</span><span class="n">is_rft</span><span class="p">():</span>
        <span class="n">adv_estimator</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;adv_estimator&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">lam</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lam&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">num_repeat</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_repeat&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">compute_advantage_ppo</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">adv_estimator</span><span class="o">=</span><span class="n">adv_estimator</span><span class="p">,</span>
            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
            <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>
            <span class="n">num_repeat</span><span class="o">=</span><span class="n">num_repeat</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Get invalid algorithm_type &#39;</span><span class="si">{</span><span class="n">algorithm_type</span><span class="si">}</span><span class="s2">&#39;.&quot;</span><span class="p">)</span></div>



<div class="viewcode-block" id="compute_advantage_opmd">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.compute_advantage_opmd">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_advantage_opmd</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">opmd_baseline</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">):</span>
    <span class="c1"># Modified from GRPO version</span>
    <span class="n">token_level_rewards</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">]</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">]</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
    <span class="n">response_length</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
    <span class="n">response_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="o">-</span><span class="n">response_length</span><span class="p">:]</span>
    <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_opmd_outcome_advantage</span><span class="p">(</span>
        <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">token_level_rewards</span><span class="p">,</span>
        <span class="n">eos_mask</span><span class="o">=</span><span class="n">response_mask</span><span class="p">,</span>
        <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
        <span class="n">opmd_baseline</span><span class="o">=</span><span class="n">opmd_baseline</span><span class="p">,</span>
        <span class="n">tau</span><span class="o">=</span><span class="n">tau</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
    <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>

    <span class="k">return</span> <span class="n">data</span></div>



<div class="viewcode-block" id="compute_advantage_ppo">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.compute_advantage_ppo">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">compute_advantage_ppo</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">adv_estimator</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">num_repeat</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># prepare response group</span>
    <span class="c1"># TODO: add other ways to estimate advantages</span>
    <span class="k">if</span> <span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GAE</span><span class="p">:</span>
        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_gae_advantage_return</span><span class="p">(</span>
            <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
            <span class="n">values</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">],</span>
            <span class="n">eos_mask</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">],</span>
            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
            <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
    <span class="k">elif</span> <span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO</span><span class="p">:</span>
        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_grpo_outcome_advantage</span><span class="p">(</span>
            <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
            <span class="n">eos_mask</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">],</span>
            <span class="n">index</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
    <span class="k">elif</span> <span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REINFORCE_PLUS_PLUS</span><span class="p">:</span>
        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_reinforce_plus_plus_outcome_advantage</span><span class="p">(</span>
            <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
            <span class="n">eos_mask</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">],</span>
            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
    <span class="k">elif</span> <span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REMAX</span><span class="p">:</span>
        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_remax_outcome_advantage</span><span class="p">(</span>
            <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
            <span class="n">reward_baselines</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;reward_baselines&quot;</span><span class="p">],</span>
            <span class="n">eos_mask</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
    <span class="k">elif</span> <span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">RLOO</span><span class="p">:</span>
        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_rloo_outcome_advantage</span><span class="p">(</span>
            <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
            <span class="n">eos_mask</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">],</span>
            <span class="n">index</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
    <span class="k">return</span> <span class="n">data</span></div>



<span class="nd">@contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_timer</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]):</span>
    <span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="k">as</span> <span class="n">timer</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="n">timing_raw</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">last</span>


<div class="viewcode-block" id="RayPPOTrainer">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.RayPPOTrainer">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">RayPPOTrainer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Note that this trainer runs on the driver process on a single CPU/GPU node.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># TODO: support each role have individual ray_worker_group_cls,</span>
    <span class="c1"># i.e., support different backend of different role</span>
<div class="viewcode-block" id="RayPPOTrainer.__init__">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.RayPPOTrainer.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">config</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">role_worker_mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Role</span><span class="p">,</span> <span class="n">WorkerType</span><span class="p">],</span>
        <span class="n">resource_pool_manager</span><span class="p">:</span> <span class="n">ResourcePoolManager</span><span class="p">,</span>
        <span class="n">ray_worker_group_cls</span><span class="p">:</span> <span class="n">RayWorkerGroup</span> <span class="o">=</span> <span class="n">RayWorkerGroup</span><span class="p">,</span>
        <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">reward_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">val_reward_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># assert torch.cuda.is_available(), &#39;cuda must be available on driver&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span> <span class="o">=</span> <span class="n">reward_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="o">=</span> <span class="n">val_reward_fn</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">hybrid_engine</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">,</span> <span class="s2">&quot;Currently, only support hybrid engine&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">role_worker_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">=}</span><span class="s2">&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span> <span class="o">=</span> <span class="n">role_worker_mapping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span> <span class="o">=</span> <span class="n">resource_pool_manager</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span> <span class="o">=</span> <span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span> <span class="o">=</span> <span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ray_worker_group_cls</span> <span class="o">=</span> <span class="n">ray_worker_group_cls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_generations_logger</span> <span class="o">=</span> <span class="n">ValidationGenerationsLogger</span><span class="p">()</span>

        <span class="c1"># define KL control</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kl_ctrl</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">get_kl_controller</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">kl_ctrl</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kl_ctrl</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">FixedKLController</span><span class="p">(</span><span class="n">kl_coef</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;algorithm_type&quot;</span><span class="p">,</span> <span class="n">AlgorithmType</span><span class="o">.</span><span class="n">PPO</span><span class="p">)</span>
            <span class="o">!=</span> <span class="n">AlgorithmType</span><span class="o">.</span><span class="n">PPO</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GAE</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO</span><span class="p">,</span>
            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REINFORCE_PLUS_PLUS</span><span class="p">,</span>
            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REMAX</span><span class="p">,</span>
            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">RLOO</span><span class="p">,</span>
        <span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_config</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_create_dataloader</span><span class="p">()</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># noqa: C901</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
        <span class="c1"># number of GPUs total</span>
        <span class="n">n_gpus</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">n_gpus_per_node</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">nnodes</span>

        <span class="c1"># 1. Check total batch size for data correctness</span>
        <span class="n">real_train_batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">n</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">real_train_batch_size</span> <span class="o">%</span> <span class="n">n_gpus</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;real_train_batch_size (</span><span class="si">{</span><span class="n">real_train_batch_size</span><span class="si">}</span><span class="s2">) must be divisible by total n_gpus (</span><span class="si">{</span><span class="n">n_gpus</span><span class="si">}</span><span class="s2">).&quot;</span>

        <span class="c1"># A helper function to check &quot;micro_batch_size&quot; vs &quot;micro_batch_size_per_gpu&quot;</span>
        <span class="c1"># We throw an error if the user sets both. The new convention is &quot;..._micro_batch_size_per_gpu&quot;.</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">check_mutually_exclusive</span><span class="p">(</span><span class="n">mbs</span><span class="p">,</span> <span class="n">mbs_per_gpu</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">mbs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">mbs_per_gpu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">] Please set at least one of &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.micro_batch_size&#39; or &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.micro_batch_size_per_gpu&#39;.&quot;</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">mbs_per_gpu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">] You have set both &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.micro_batch_size&#39; AND &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.micro_batch_size_per_gpu&#39;. Please remove &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.micro_batch_size&#39; &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;because only &#39;*_micro_batch_size_per_gpu&#39; is supported (the former is deprecated).&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
            <span class="c1"># actor: ppo_micro_batch_size vs. ppo_micro_batch_size_per_gpu</span>
            <span class="n">check_mutually_exclusive</span><span class="p">(</span>
                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span><span class="p">,</span>
                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size_per_gpu</span><span class="p">,</span>
                <span class="s2">&quot;actor_rollout_ref.actor&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># reference: log_prob_micro_batch_size vs. log_prob_micro_batch_size_per_gpu</span>
            <span class="n">check_mutually_exclusive</span><span class="p">(</span>
                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">ref</span><span class="o">.</span><span class="n">log_prob_micro_batch_size</span><span class="p">,</span>
                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">ref</span><span class="o">.</span><span class="n">log_prob_micro_batch_size_per_gpu</span><span class="p">,</span>
                <span class="s2">&quot;actor_rollout_ref.ref&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1">#  The rollout section also has log_prob_micro_batch_size vs. log_prob_micro_batch_size_per_gpu</span>
            <span class="n">check_mutually_exclusive</span><span class="p">(</span>
                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">log_prob_micro_batch_size</span><span class="p">,</span>
                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">log_prob_micro_batch_size_per_gpu</span><span class="p">,</span>
                <span class="s2">&quot;actor_rollout_ref.rollout&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
            <span class="c1"># Check for critic micro-batch size conflicts</span>
            <span class="n">check_mutually_exclusive</span><span class="p">(</span>
                <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span><span class="p">,</span>
                <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size_per_gpu</span><span class="p">,</span>
                <span class="s2">&quot;critic&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Check for reward model micro-batch size conflicts</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">enable</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
            <span class="n">check_mutually_exclusive</span><span class="p">(</span>
                <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">micro_batch_size</span><span class="p">,</span>
                <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">micro_batch_size_per_gpu</span><span class="p">,</span>
                <span class="s2">&quot;reward_model&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Actor</span>
        <span class="c1"># if NOT dynamic_bsz, we must ensure:</span>
        <span class="c1">#    ppo_mini_batch_size is divisible by ppo_micro_batch_size</span>
        <span class="c1">#    ppo_micro_batch_size * sequence_parallel_size &gt;= n_gpus</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span>
            <span class="p">)</span>
            <span class="n">sp_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span>
                    <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span>
                    <span class="o">==</span> <span class="mi">0</span>
                <span class="p">)</span>
                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">*</span> <span class="n">sp_size</span> <span class="o">&gt;=</span> <span class="n">n_gpus</span>

        <span class="c1"># critic</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span>
            <span class="n">sp_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span> <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">==</span> <span class="mi">0</span>
                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">*</span> <span class="n">sp_size</span> <span class="o">&gt;=</span> <span class="n">n_gpus</span>

        <span class="c1"># Check if use_remove_padding is enabled when using sequence parallelism for fsdp</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;fsdp&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
                <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">ref</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
            <span class="p">):</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_remove_padding</span>
                <span class="p">),</span> <span class="s2">&quot;When using sequence parallelism for actor/ref policy, you must enable `use_remove_padding`.&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;fsdp&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_remove_padding</span>
                <span class="p">),</span> <span class="s2">&quot;When using sequence parallelism for critic, you must enable `use_remove_padding`.&quot;</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_batch_size&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;WARNING: val_batch_size is deprecated. Validation datasets are sent to inference engines as a whole batch, which will schedule the memory themselves.&quot;</span>
            <span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[validate_config] All configuration checks passed successfully!&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># TODO: we have to make sure the batch size is divisible by the dp size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">RLHFDataset</span><span class="p">(</span>
            <span class="n">parquet_files</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_files</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">processor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span>
            <span class="n">prompt_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">prompt_key</span><span class="p">,</span>
            <span class="n">image_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;image_key&quot;</span><span class="p">,</span> <span class="s2">&quot;images&quot;</span><span class="p">),</span>
            <span class="n">max_prompt_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="n">filter_prompts</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_raw_chat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;return_raw_chat&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
            <span class="n">truncation</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># use sampler for better ckpt resume</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
            <span class="n">train_dataloader_generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
            <span class="n">train_dataloader_generator</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span>
                <span class="n">data_source</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">train_dataloader_generator</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sampler</span> <span class="o">=</span> <span class="n">SequentialSampler</span><span class="p">(</span><span class="n">data_source</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">StatefulDataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span><span class="p">,</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span> <span class="o">=</span> <span class="n">RLHFDataset</span><span class="p">(</span>
            <span class="n">parquet_files</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_files</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">processor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span>
            <span class="n">prompt_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">prompt_key</span><span class="p">,</span>
            <span class="n">image_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;image_key&quot;</span><span class="p">,</span> <span class="s2">&quot;images&quot;</span><span class="p">),</span>
            <span class="n">max_prompt_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span><span class="p">,</span>
            <span class="n">filter_prompts</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_raw_chat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;return_raw_chat&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
            <span class="n">truncation</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span> <span class="o">=</span> <span class="n">StatefulDataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span>
            <span class="c1"># Validation datasets are sent to inference engines as a whole batch,</span>
            <span class="c1"># which will schedule the memory themselves.</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">),</span>
            <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="p">),</span> <span class="s2">&quot;Validation dataloader must have a single batch, which inference engines will schedule the memory themselves.&quot;</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of train dataloader: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># inject total_training_steps to actor/critic optim_config. This is hacky.</span>
        <span class="n">total_training_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">total_training_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_training_steps</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="o">=</span> <span class="n">total_training_steps</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total training steps: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">open_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="o">=</span> <span class="n">total_training_steps</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="o">=</span> <span class="n">total_training_steps</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_maybe_log_val_generations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">scores</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Log a table of validation samples to the configured logger (wandb or swanlab)&quot;&quot;&quot;</span>

        <span class="n">generations_to_log</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">val_generations_to_log_to_wandb</span>

        <span class="k">if</span> <span class="n">generations_to_log</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

        <span class="c1"># Create tuples of (input, output, score) and sort by input text</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">scores</span><span class="p">))</span>
        <span class="n">samples</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Sort by input text</span>

        <span class="c1"># Use fixed random seed for deterministic shuffling</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">rng</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

        <span class="c1"># Take first N samples after shuffling</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[:</span><span class="n">generations_to_log</span><span class="p">]</span>

        <span class="c1"># Log to each configured logger</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_generations_logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">reward_tensor_lst</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">data_source_lst</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Lists to collect samples for the table</span>
        <span class="n">sample_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sample_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sample_scores</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">test_data</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">:</span>
            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

            <span class="c1"># we only do validation on rule-based rm</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">enable</span>
                <span class="ow">and</span> <span class="n">test_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;reward_model&quot;</span><span class="p">][</span><span class="s2">&quot;style&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="p">{}</span>

            <span class="c1"># Store original inputs</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
            <span class="n">input_texts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">input_ids</span>
            <span class="p">]</span>
            <span class="n">sample_inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">input_texts</span><span class="p">)</span>

            <span class="k">if</span> <span class="s2">&quot;multi_modal_inputs&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">test_gen_batch</span> <span class="o">=</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                    <span class="n">batch_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">],</span>
                    <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="p">[</span>
                        <span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;multi_modal_data&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;multi_modal_inputs&quot;</span><span class="p">,</span>
                    <span class="p">],</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">test_gen_batch</span> <span class="o">=</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                    <span class="n">batch_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">],</span>
                    <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">],</span>
                <span class="p">)</span>

            <span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;eos_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                <span class="s2">&quot;pad_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
                <span class="s2">&quot;recompute_log_prob&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;do_sample&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;validate&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="c1"># pad to be divisible by dp_size</span>
            <span class="n">test_gen_batch_padded</span><span class="p">,</span> <span class="n">pad_size</span> <span class="o">=</span> <span class="n">pad_dataproto_to_divisor</span><span class="p">(</span>
                <span class="n">test_gen_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">world_size</span>
            <span class="p">)</span>
            <span class="n">test_output_gen_batch_padded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">generate_sequences</span><span class="p">(</span>
                <span class="n">test_gen_batch_padded</span>
            <span class="p">)</span>
            <span class="c1"># unpad</span>
            <span class="n">test_output_gen_batch</span> <span class="o">=</span> <span class="n">unpad_dataproto</span><span class="p">(</span><span class="n">test_output_gen_batch_padded</span><span class="p">,</span> <span class="n">pad_size</span><span class="o">=</span><span class="n">pad_size</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;validation generation end&quot;</span><span class="p">)</span>

            <span class="c1"># Store generated outputs</span>
            <span class="n">output_ids</span> <span class="o">=</span> <span class="n">test_output_gen_batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
            <span class="n">output_texts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">output_ids</span>
            <span class="p">]</span>
            <span class="n">sample_outputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_texts</span><span class="p">)</span>

            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">test_output_gen_batch</span><span class="p">)</span>

            <span class="c1"># evaluate using reward_function</span>
            <span class="n">reward_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>

            <span class="c1"># Store scores</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">reward_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">sample_scores</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

            <span class="n">reward_tensor_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward_tensor</span><span class="p">)</span>
            <span class="n">data_source_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;data_source&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;unknown&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">reward_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_log_val_generations</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">sample_inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">sample_outputs</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="n">sample_scores</span>
        <span class="p">)</span>

        <span class="n">reward_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">reward_tensor_lst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>  <span class="c1"># (batch_size,)</span>
        <span class="n">data_sources</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">data_source_lst</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># evaluate test_score based on data source</span>
        <span class="n">data_source_reward</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reward_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">data_source</span> <span class="o">=</span> <span class="n">data_sources</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">data_source</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data_source_reward</span><span class="p">:</span>
                <span class="n">data_source_reward</span><span class="p">[</span><span class="n">data_source</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">data_source_reward</span><span class="p">[</span><span class="n">data_source</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="n">metric_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">data_source</span><span class="p">,</span> <span class="n">rewards</span> <span class="ow">in</span> <span class="n">data_source_reward</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">metric_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;val/test_score/</span><span class="si">{</span><span class="n">data_source</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">metric_dict</span>

<div class="viewcode-block" id="RayPPOTrainer.init_workers">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.RayPPOTrainer.init_workers">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_workers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Init resource pool and worker group&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">create_resource_pool</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">pool</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">pool</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">resource_pool_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="p">}</span>

        <span class="c1"># create actor and rollout</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">:</span>
            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span><span class="p">)</span>
            <span class="n">actor_rollout_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span>
                <span class="bp">cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span><span class="p">],</span>
                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="p">,</span>
                <span class="n">role</span><span class="o">=</span><span class="s2">&quot;actor&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;actor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">actor_rollout_cls</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="c1"># create critic</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">Critic</span><span class="p">)</span>
            <span class="n">critic_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span>
                <span class="bp">cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">Critic</span><span class="p">],</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;critic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">critic_cls</span>

        <span class="c1"># create reference policy if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span><span class="p">)</span>
            <span class="n">ref_policy_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span><span class="p">],</span>
                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="p">,</span>
                <span class="n">role</span><span class="o">=</span><span class="s2">&quot;ref&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;ref&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ref_policy_cls</span>

        <span class="c1"># create a reward model if reward_fn is None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
            <span class="c1"># we create a RM here</span>
            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span><span class="p">)</span>
            <span class="n">rm_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span><span class="p">],</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;rm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rm_cls</span>

        <span class="c1"># initialize WorkerGroup</span>
        <span class="c1"># NOTE: if you want to use a different resource pool for each role, which can support different parallel size,</span>
        <span class="c1"># you should not use `create_colocated_worker_cls`. Instead, directly pass different resource pool to different worker groups.</span>
        <span class="c1"># See https://github.com/volcengine/verl/blob/master/examples/ray/tutorial.ipynb for more information.</span>
        <span class="n">all_wg</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wg_dicts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">resource_pool</span><span class="p">,</span> <span class="n">class_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">worker_dict_cls</span> <span class="o">=</span> <span class="n">create_colocated_worker_cls</span><span class="p">(</span><span class="n">class_dict</span><span class="o">=</span><span class="n">class_dict</span><span class="p">)</span>
            <span class="n">wg_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ray_worker_group_cls</span><span class="p">(</span>
                <span class="n">resource_pool</span><span class="o">=</span><span class="n">resource_pool</span><span class="p">,</span> <span class="n">ray_cls_with_init</span><span class="o">=</span><span class="n">worker_dict_cls</span>
            <span class="p">)</span>
            <span class="n">spawn_wg</span> <span class="o">=</span> <span class="n">wg_dict</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">prefix_set</span><span class="o">=</span><span class="n">class_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="n">all_wg</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">spawn_wg</span><span class="p">)</span>
            <span class="c1"># keep the referece of WorkerDict to support ray &gt;= 2.31. Ref: https://github.com/ray-project/ray/pull/45699</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wg_dicts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wg_dict</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;critic&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;ref&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;rm&quot;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>

        <span class="c1"># we should create rollout at the end so that vllm can have a better estimation of kv cache memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;actor&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># path: given_path + `/global_step_{global_steps}` + `/actor`</span>
        <span class="n">local_global_step_folder</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">default_local_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;global_step_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;local_global_step_folder: </span><span class="si">{</span><span class="n">local_global_step_folder</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">actor_local_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">local_global_step_folder</span><span class="p">,</span> <span class="s2">&quot;actor&quot;</span><span class="p">)</span>

        <span class="n">actor_remote_path</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">default_hdfs_dir</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">default_hdfs_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;global_step_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;actor&quot;</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">remove_previous_ckpt_in_save</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;remove_previous_ckpt_in_save&quot;</span><span class="p">,</span> <span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">remove_previous_ckpt_in_save</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;Warning: remove_previous_ckpt_in_save is deprecated, set max_actor_ckpt_to_keep=1 and max_critic_ckpt_to_keep=1 instead&quot;</span>
            <span class="p">)</span>
        <span class="n">max_actor_ckpt_to_keep</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;max_actor_ckpt_to_keep&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">remove_previous_ckpt_in_save</span>
            <span class="k">else</span> <span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">max_critic_ckpt_to_keep</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;max_critic_ckpt_to_keep&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">remove_previous_ckpt_in_save</span>
            <span class="k">else</span> <span class="mi">1</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span>
            <span class="n">actor_local_path</span><span class="p">,</span>
            <span class="n">actor_remote_path</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span>
            <span class="n">max_ckpt_to_keep</span><span class="o">=</span><span class="n">max_actor_ckpt_to_keep</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
            <span class="n">critic_local_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">local_global_step_folder</span><span class="p">,</span> <span class="s2">&quot;critic&quot;</span><span class="p">)</span>
            <span class="n">critic_remote_path</span> <span class="o">=</span> <span class="p">(</span>
                <span class="kc">None</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">default_hdfs_dir</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">default_hdfs_dir</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;global_step_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;critic&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span>
                <span class="n">critic_local_path</span><span class="p">,</span>
                <span class="n">critic_remote_path</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span>
                <span class="n">max_ckpt_to_keep</span><span class="o">=</span><span class="n">max_critic_ckpt_to_keep</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># save dataloader</span>
        <span class="n">dataloader_local_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">local_global_step_folder</span><span class="p">,</span> <span class="s2">&quot;data.pt&quot;</span><span class="p">)</span>
        <span class="n">dataloader_state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">dataloader_state_dict</span><span class="p">,</span> <span class="n">dataloader_local_path</span><span class="p">)</span>

        <span class="c1"># latest checkpointed iteration tracker (for atomic usage)</span>
        <span class="n">local_latest_checkpointed_iteration</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">default_local_dir</span><span class="p">,</span> <span class="s2">&quot;latest_checkpointed_iteration.txt&quot;</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">local_latest_checkpointed_iteration</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">resume_mode</span> <span class="o">==</span> <span class="s2">&quot;disable&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>

        <span class="c1"># load from hdfs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">default_hdfs_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;load from hdfs is not implemented yet&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">checkpoint_folder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">default_local_dir</span>  <span class="c1"># TODO: check path</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isabs</span><span class="p">(</span><span class="n">checkpoint_folder</span><span class="p">):</span>
                <span class="n">working_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
                <span class="n">checkpoint_folder</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">checkpoint_folder</span><span class="p">)</span>
            <span class="n">global_step_folder</span> <span class="o">=</span> <span class="n">find_latest_ckpt_path</span><span class="p">(</span><span class="n">checkpoint_folder</span><span class="p">)</span>  <span class="c1"># None if no latest</span>

        <span class="c1"># find global_step_folder</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">resume_mode</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">global_step_folder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training from scratch&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">resume_mode</span> <span class="o">==</span> <span class="s2">&quot;resume_path&quot;</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">resume_from_path</span><span class="p">,</span> <span class="nb">str</span>
                <span class="p">),</span> <span class="s2">&quot;resume ckpt must be str type&quot;</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="s2">&quot;global_step_&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">resume_from_path</span>
                <span class="p">),</span> <span class="s2">&quot;resume ckpt must specify the global_steps&quot;</span>
                <span class="n">global_step_folder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">resume_from_path</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isabs</span><span class="p">(</span><span class="n">global_step_folder</span><span class="p">):</span>
                    <span class="n">working_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
                    <span class="n">global_step_folder</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">global_step_folder</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Load from checkpoint folder: </span><span class="si">{</span><span class="n">global_step_folder</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># set global step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">global_step_folder</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;global_step_&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting global step to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Resuming from </span><span class="si">{</span><span class="n">global_step_folder</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">actor_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">global_step_folder</span><span class="p">,</span> <span class="s2">&quot;actor&quot;</span><span class="p">)</span>
        <span class="n">critic_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">global_step_folder</span><span class="p">,</span> <span class="s2">&quot;critic&quot;</span><span class="p">)</span>
        <span class="c1"># load actor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span>
            <span class="n">actor_path</span><span class="p">,</span> <span class="n">del_local_after_load</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">del_local_ckpt_after_load</span>
        <span class="p">)</span>
        <span class="c1"># load critic</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span>
                <span class="n">critic_path</span><span class="p">,</span> <span class="n">del_local_after_load</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">del_local_ckpt_after_load</span>
            <span class="p">)</span>

        <span class="c1"># load dataloader,</span>
        <span class="c1"># TODO: from remote not implemented yet</span>
        <span class="n">dataloader_local_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">global_step_folder</span><span class="p">,</span> <span class="s2">&quot;data.pt&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dataloader_local_path</span><span class="p">):</span>
            <span class="n">dataloader_state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">dataloader_local_path</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">dataloader_state_dict</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Warning: No dataloader state found at </span><span class="si">{</span><span class="n">dataloader_local_path</span><span class="si">}</span><span class="s2">, will start from scratch&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_balance_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">logging_prefix</span><span class="o">=</span><span class="s2">&quot;global_seqlen&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reorder the data on single controller such that each dp rank gets similar total tokens&quot;&quot;&quot;</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">global_seqlen_lst</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="p">)</span>  <span class="c1"># (train_batch_size,)</span>
        <span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">world_size</span>
        <span class="n">global_partition_lst</span> <span class="o">=</span> <span class="n">get_seqlen_balanced_partitions</span><span class="p">(</span>
            <span class="n">global_seqlen_lst</span><span class="p">,</span> <span class="n">k_partitions</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span> <span class="n">equal_size</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="c1"># reorder based on index. The data will be automatically equally partitioned by dispatch function</span>
        <span class="n">global_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">j</span> <span class="k">for</span> <span class="n">partition</span> <span class="ow">in</span> <span class="n">global_partition_lst</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">partition</span><span class="p">])</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">global_idx</span><span class="p">)</span>
        <span class="n">global_balance_stats</span> <span class="o">=</span> <span class="n">log_seqlen_unbalance</span><span class="p">(</span>
            <span class="n">seqlen_list</span><span class="o">=</span><span class="n">global_seqlen_lst</span><span class="p">,</span> <span class="n">partitions</span><span class="o">=</span><span class="n">global_partition_lst</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">logging_prefix</span>
        <span class="p">)</span>
        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">global_balance_stats</span><span class="p">)</span>

<div class="viewcode-block" id="RayPPOTrainer.fit">
<a class="viewcode-back" href="../../../../build_api/trinity.trainer.verl.html#trinity.trainer.verl.ray_trainer.RayPPOTrainer.fit">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># noqa: C901</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The training loop of PPO.</span>
<span class="sd">        The driver process only need to call the compute functions of the worker group through RPC to construct the PPO dataflow.</span>
<span class="sd">        The light-weight advantage computation is done on the driver process.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">omegaconf</span><span class="w"> </span><span class="kn">import</span> <span class="n">OmegaConf</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.tracking</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tracking</span>

        <span class="n">logger</span> <span class="o">=</span> <span class="n">Tracking</span><span class="p">(</span>
            <span class="n">project_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">project_name</span><span class="p">,</span>
            <span class="n">experiment_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">experiment_name</span><span class="p">,</span>
            <span class="n">default_backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># load checkpoint before doing anything</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_load_checkpoint</span><span class="p">()</span>

        <span class="c1"># perform validation before training</span>
        <span class="c1"># currently, we only support validation using the reward_function.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_before_train&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="n">val_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>
            <span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial validation metrics: </span><span class="si">{</span><span class="n">val_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">val_metrics</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="k">return</span>

        <span class="c1"># add tqdm</span>
        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span>
            <span class="n">total</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span><span class="p">,</span> <span class="n">initial</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training Progress&quot;</span>
        <span class="p">)</span>

        <span class="c1"># we start from step 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">last_val_metrics</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">:</span>
                <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">timing_raw</span> <span class="o">=</span> <span class="p">{}</span>

                <span class="n">batch</span><span class="p">:</span> <span class="n">DataProto</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">batch_dict</span><span class="p">)</span>

                <span class="c1"># pop those keys for generation</span>
                <span class="k">if</span> <span class="s2">&quot;multi_modal_inputs&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">gen_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                        <span class="n">batch_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">],</span>
                        <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="p">[</span>
                            <span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;multi_modal_data&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;multi_modal_inputs&quot;</span><span class="p">,</span>
                        <span class="p">],</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">gen_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                        <span class="n">batch_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">],</span>
                        <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">],</span>
                    <span class="p">)</span>

                <span class="n">is_last_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span>

                <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                    <span class="c1"># generate a batch</span>
                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                        <span class="n">gen_batch_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">generate_sequences</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">)</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REMAX</span><span class="p">:</span>
                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;gen_max&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                            <span class="n">gen_baseline_batch</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">)</span>
                            <span class="n">gen_baseline_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;do_sample&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                            <span class="n">gen_baseline_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">generate_sequences</span><span class="p">(</span>
                                <span class="n">gen_baseline_batch</span>
                            <span class="p">)</span>

                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">gen_baseline_output</span><span class="p">)</span>
                            <span class="n">reward_baseline_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                            <span class="n">reward_baseline_tensor</span> <span class="o">=</span> <span class="n">reward_baseline_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

                            <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">batch_keys</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">gen_baseline_output</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

                            <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;reward_baselines&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_baseline_tensor</span>

                            <span class="k">del</span> <span class="n">gen_baseline_batch</span><span class="p">,</span> <span class="n">gen_baseline_output</span>

                    <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                        <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">))],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span>
                    <span class="p">)</span>
                    <span class="c1"># repeat to align with repeated responses in rollout</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                        <span class="n">repeat_times</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">interleave</span><span class="o">=</span><span class="kc">True</span>
                    <span class="p">)</span>
                    <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">gen_batch_output</span><span class="p">)</span>

                    <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_response_mask</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

                    <span class="c1"># balance the number of valid tokens on each dp rank.</span>
                    <span class="c1"># Note that this breaks the order of data inside the batch.</span>
                    <span class="c1"># Please take care when you implement group based adv computation such as GRPO and rloo</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">balance_batch</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_balance_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>

                    <span class="c1"># compute global_valid tokens</span>
                    <span class="n">batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;global_token_num&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                        <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

                    <span class="c1"># recompute old_log_probs</span>
                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;old_log_prob&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                        <span class="n">old_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">compute_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                        <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">old_log_prob</span><span class="p">)</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
                        <span class="c1"># compute reference log_prob</span>
                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;ref&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                            <span class="n">ref_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span><span class="o">.</span><span class="n">compute_ref_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">ref_log_prob</span><span class="p">)</span>

                    <span class="c1"># compute values</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">compute_values</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>

                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;adv&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                        <span class="c1"># compute scores. Support both model and function-based.</span>
                        <span class="c1"># We first compute the scores using reward model. Then, we call reward_fn to combine</span>
                        <span class="c1"># the results from reward model and rule-based results.</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
                            <span class="c1"># we first compute reward model score</span>
                            <span class="n">reward_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span><span class="o">.</span><span class="n">compute_rm_score</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">reward_tensor</span><span class="p">)</span>

                        <span class="c1"># we combine with rule-based rm</span>
                        <span class="n">reward_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                        <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_tensor</span>

                        <span class="c1"># compute rewards. apply_kl_penalty if available</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_kl_loss&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                            <span class="n">batch</span><span class="p">,</span> <span class="n">kl_metrics</span> <span class="o">=</span> <span class="n">apply_kl_penalty</span><span class="p">(</span>
                                <span class="n">batch</span><span class="p">,</span>
                                <span class="n">kl_ctrl</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kl_ctrl</span><span class="p">,</span>
                                <span class="n">kl_penalty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">kl_penalty</span><span class="p">,</span>
                            <span class="p">)</span>
                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kl_metrics</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span>

                        <span class="c1"># compute advantages, executed on the driver process</span>
                        <span class="n">algorithm_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                            <span class="s2">&quot;algorithm_type&quot;</span><span class="p">,</span> <span class="n">AlgorithmType</span><span class="o">.</span><span class="n">PPO</span>
                        <span class="p">)</span>
                        <span class="n">tau</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tau&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                        <span class="n">opmd_baseline</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                            <span class="s2">&quot;opmd_baseline&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span>
                        <span class="p">)</span>
                        <span class="n">batch</span> <span class="o">=</span> <span class="n">compute_advantage</span><span class="p">(</span>
                            <span class="n">batch</span><span class="p">,</span>
                            <span class="n">algorithm_type</span><span class="o">=</span><span class="n">algorithm_type</span><span class="p">,</span>
                            <span class="n">adv_estimator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span><span class="p">,</span>
                            <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
                            <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">lam</span><span class="p">,</span>
                            <span class="n">num_repeat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
                            <span class="c1"># additional config params for OPMD</span>
                            <span class="n">tau</span><span class="o">=</span><span class="n">tau</span><span class="p">,</span>
                            <span class="n">opmd_baseline</span><span class="o">=</span><span class="n">opmd_baseline</span><span class="p">,</span>
                        <span class="p">)</span>

                    <span class="c1"># update critic</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;update_critic&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                            <span class="n">critic_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">update_critic</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                        <span class="n">critic_output_metrics</span> <span class="o">=</span> <span class="n">reduce_metrics</span><span class="p">(</span><span class="n">critic_output</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;metrics&quot;</span><span class="p">])</span>
                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">critic_output_metrics</span><span class="p">)</span>

                    <span class="c1"># implement critic warmup</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">critic_warmup</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">:</span>
                        <span class="c1"># update actor</span>
                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;update_actor&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                            <span class="n">actor_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">update_actor</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                        <span class="n">actor_output_metrics</span> <span class="o">=</span> <span class="n">reduce_metrics</span><span class="p">(</span><span class="n">actor_output</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;metrics&quot;</span><span class="p">])</span>
                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">actor_output_metrics</span><span class="p">)</span>

                    <span class="c1"># validate</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_freq</span> <span class="o">&gt;</span> <span class="mi">0</span>
                        <span class="ow">and</span> <span class="p">(</span><span class="n">is_last_step</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="p">):</span>
                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;testing&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                            <span class="n">val_metrics</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>
                            <span class="k">if</span> <span class="n">is_last_step</span><span class="p">:</span>
                                <span class="n">last_val_metrics</span> <span class="o">=</span> <span class="n">val_metrics</span>
                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_metrics</span><span class="p">)</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span>
                        <span class="n">is_last_step</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="mi">0</span>
                    <span class="p">):</span>
                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;save_checkpoint&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_save_checkpoint</span><span class="p">()</span>

                <span class="c1"># collect metrics</span>
                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_data_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">use_critic</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">))</span>
                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_timing_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">timing_raw</span><span class="o">=</span><span class="n">timing_raw</span><span class="p">))</span>

                <span class="c1"># Implement actual tflpo and theoretical tflpo</span>
                <span class="n">n_gpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_n_gpus</span><span class="p">()</span>
                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="n">compute_throughout_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">timing_raw</span><span class="o">=</span><span class="n">timing_raw</span><span class="p">,</span> <span class="n">n_gpus</span><span class="o">=</span><span class="n">n_gpus</span><span class="p">)</span>
                <span class="p">)</span>

                <span class="c1"># TODO: make a canonical logger that supports various backend</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">is_last_step</span><span class="p">:</span>
                    <span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final validation metrics: </span><span class="si">{</span><span class="n">last_val_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                    <span class="k">return</span>

                <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">+=</span> <span class="mi">1</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Trinity-RFT Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>