project: "Trinity-RFT-countdown-experience-replay"
name: "qwen2.5-1.5B-countdown"
checkpoint_root_dir: ${oc.env:TRINITY_CHECKPOINT_ROOT_DIR,./checkpoints}
algorithm:
  algorithm_type: ppo
  repeat_times: 5
  optimizer:
    lr: 1e-6
model:
  model_path: ${oc.env:TRINITY_MODEL_PATH,Qwen/Qwen2.5-1.5B-Instruct}
  max_response_tokens: 1024
  max_model_len: 2048
cluster:
  node_num: 1
  gpu_per_node: 7
buffer:
  total_epochs: 20
  batch_size: 96
  explorer_input:
    taskset:
      name: countdown
      storage_type: file
      path: 'countdown_dataset/oneshot-split'
      format:
        prompt_key: 'question'
        response_key: 'answer'
      rollout_args:
        temperature: 1.0
        logprobs: 0
      default_workflow_type: 'math_workflow'
      default_reward_fn_type: 'countdown_reward'
  trainer_input:
    experience_buffer:
      name: experience_buffer
      storage_type: queue
      replay_buffer:
        enable: true
        reuse_cooldown_time: 40
        priority_fn: decay_limit_randomization
        # priority_fn_args: use default values
explorer:
  eval_interval: 100
  runner_per_model: 8
  rollout_model:
    engine_num: 1  # allocate 1 GPU for explorer
    tensor_parallel_size: 1
    enable_prefix_caching: false
    enforce_eager: true
    dtype: bfloat16
    seed: 42
synchronizer:
  sync_method: 'nccl'
  sync_style: dynamic_by_explorer  # set to "fixed" for baseline
  sync_interval: 10
  sync_timeout: 1200
trainer:
  save_interval: 100
  grad_clip: 1.0
  use_dynamic_bsz: true
  max_token_len_per_gpu: 10240
  ulysses_sequence_parallel_size: 1
  trainer_config:
    actor_rollout_ref:
      actor:
        checkpoint:
          load_contents: ['model', 'hf_model', 'optimizer', 'extra']
          save_contents: ['model', 'hf_model', 'optimizer', 'extra']
    critic:
      optim:
        lr: 1e-5
      ppo_max_token_len_per_gpu: 20480
      forward_max_token_len_per_gpu: 20480
      cliprange_value: 0.5
    trainer:
      max_actor_ckpt_to_keep: 5
      max_critic_ckpt_to_keep: 5
